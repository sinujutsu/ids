% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009

\documentclass{acm_proc_article-sp}
\usepackage{graphicx}
\setlength\parindent{12pt}
%\usepackage{cite}

\begin{document}

\title{Sound the Alarm!\\A Survey of Modern Intrusion Detection Methodologies}\numberofauthors{2} 

\author{
% 1st. author
\alignauthor
Erin Jamroz
       \affaddr{University of Puget Sound}\\
       \affaddr{1500 N. Alder St.}\\
       \affaddr{Tacoma, WA}\\
       \email{ejamroz@pugetsound.edu}
% 2nd. author
\alignauthor
Jacob Fuhrman
       \affaddr{University of Puget Sound}\\
       \affaddr{1500 N. Alder St.}\\
       \affaddr{Tacoma, WA}\\
       \email{jfuhrman@pugetsound.edu}\\       
}

\maketitle
% SEE OUR PROPOSAL FOR HOW TO DO CITATIONS IN TEXT, I WILL HANDLE THE BIBTEX 
% WHEN WE ARE DONE! 

\begin{abstract}
%There was a nice paragraph here, where did it go? It was in the PDF, and not the .tex document....
\end{abstract}

\section{Introduction}
	In a world of increasing connectivity and nearly ubiquitous technology, the importance of computer security has grown with the user base it has sought to protect. As the "smartphone" has come into such prevalent use in the U.S. and abroad, millions of people use these minicomputers daily. In addition, users of modern technology interact with tens or hundreds of other devices each day, from wireless networks, to connections across their devices at home, to accessing content on the web. With daily access to these services becoming so important to such a massive user base, it is only natural that they would become attractive targets to attackers, and thus all the more important to defend. There are many approaches available to defending a given system or a network of systems, but one that has risen in scientific interest lately is the Intrusion Detection System (IDS), a software suite intended to detect attacks made against a network or system and notify those charged with protecting it.
	
	Intrusion detection is the process of detecting unauthorized use of a system and alerting the proper authorities of such misuse. Intrusion detection systems (IDS) are the systems used to to detect these misuses and aid in their defense. 
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.5\textwidth]{idsBreakdown.png}
		\caption{A general breakdown of IDSs by Audit System and Event Analysis. Image taken from \cite{Alenezi2012}}
		\label{breakdown}
	\end{figure}
    % Will need some filler intro stuff here

    % In this intro, explicitly state that the following information came from [Mell, Peter @ EDPACS] 
    \subsection{Audit Systems}
    	This section will breakdown IDSs by their audit system, which describes the source of the data that they analyse for intrusions. There are three main types of audit systems: \emph{Host-Based}, \emph{Network-Based}, and \emph{Application-Based}.
    	\subsubsection{Host-Based} %Citations needed: Taylor&Mell
    		Host-Based IDSs (HIDS) are characterized by having detection sensors on each individual machine within a network. These types of systems monitor an individual computer's system logs to detect attacks. HIDSs are able to detect attacks with much more specificity than network-based systems because they are able to monitor individual processes on an particular machine for malicious activity. 
    		
    		There are many advantages to using a HIDS. First, and fore most, they are able to detect attacks that network-based sensors cannot, because they are running on the host machine. Next, unlike network-based sensors, they are fully functional within both switched, and encrypted networks because their audit source is independent of network traffic, and they are able to use host resources to decrypt traffic before analysis.
   % The following is Jake's version of host-based stuff. Merge? Delete?    
   %This whole section is based on the IDS Newsletter article by Taylor and Mell, and could use additional flavor from other authors.
   % Host based audit systems are audit systems that rest on the host that they monitor, and thus analyze the activity on only one computer. They are primarily used due to the extremely high granularity of analysis they provide, as they can observe and monitor every aspect of a running system, from running processes and services, to who launched them and when. In the case of many attacks on an individual system, this finely detailed analysis is essential, as it allows host-based systems to detect attacks that cannot be observed from anywhere but the host itself (such as network traffic in a network-based system, which will be explained in the next section). Host-based audit systems are also compatible with systems that converse using encrypted traffic, if configured properly, as the traffic needs to be decrypted at some point before reaching the user, at which point the host-based system can intercept it. This way the traffic can remain secure within a layer of encryption, and the host can remain secure and analyzable by the audit system, creating a solid series of defense mechanisms that do not conflict with one another. Similarly, host-based audit systems can operate without handicaps of any kind in switched networks, as the physical layout of the network does not affect the host system, a point that will also be made more relevant once network-based audit systems are explained. 
    
    %However, host-based audit systems do lend themselves to several key flaws. The first flaw, and arguably the most regrettable considering the impressive list of strengths listed above, is the fact that host-based systems are vulnerable to attack. Simply, the host-based system resides on the system it monitors, and thus a clever attacker, if they can locate where the software sits on the system, can disable or perhaps even destroy a host-based audit system if they gain access to the computer it rests on. The second flaw is that host-based systems, by design, have only the resources of the host system they reside on and monitor available to perform their analysis with, and cannot be supplemented in this task. Thus in the perhaps rare scenario in which one possess an important system that needs to be protected at the host-level, but the system is composed of low-performance hardware, a host-based solution is simply not feasible. Moreover, on systems with reasonably powerful hardware, one could imagine the scenario in which the system, if it is acting as a webserver or providing services to a large number of clients, may experience a large enough request for said services that its resources could become tied up in managing server-client interactions to the extent that a host-based system is unable to perform its analysis. This, of course, is a critical flaw in the system's design, as the behavior of the increasingly prevalent Denial of Service attack exploits just this sort of resource-binding potential. Thus the efficacy of host-based systems is predicated by the amount of resources a system has to work with, making such systems incredibly vulnerable to Denial of Service attacks.
    	\subsubsection{Network-Based}
    		Network-based IDSs (NIDS) are characterized by having detection sensors placed at network hubs, such as routers, rather than on each individual machine in a network. These types of systems work by monitoring network traffic looking for patterns in flow or analyzing packet headers for trends. These are the most commonly used types of systems today. 
    		
    		NIDSs have many advantages over a host-based system, mainly that fewer sensors are required to cover the entire network, which also means less installation time and maintenance. These types of systems also have little to no impact on network performance, because they are sensors that traffic is simply routed through. As they are their own independent system residing on the network, they can be set up in such a way that they are invisible to outsiders. This hidden nature also makes them very insulated from attack themselves, which is a large advantage for network administrators. 
    		
    		However, these systems are not without their drawbacks. It has been shown that in periods of high network load, these systems performance drops due to an inability to process all incoming packets. As such, they could fail to detect an attack that was launched during one of these periods. The effectiveness of these types of systems also drops in switched networks, because switches subdivide network traffic such that a NIDS can no longer monitor all traffic on the network because much of it is hidden behind a switches. Finally, NIDSs are are unable to analyse encrypted traffic. This incapability is a major drawback, especially in this day in age, as more and more traffic is being moved to encrypted channels of communication. 		
    	\subsubsection{Hybrid System}
    	%Combine features of both and show a great deal of promise 
    \subsection{Event Analysis}
   	This section will further subdivide and discuss IDSs by event analysis, which describes the method of detection used, given a particular audit source of data. These detection methods fall into two major categories: \emph{Signature Detection} and \emph{Anomaly Detection}. Signature based methods are much more common in practice, but anomaly detection is an area of much research and promise. A summary of both strategies can be found in \ref{comparison}.
	    \subsubsection{Signature Detection} 
	    	Signature Detection is a complex subject, but can be easily summarized without losing critical details. This section is largely a summary of simple descriptions of the principles of Signature Detection from \cite{Taylor2006}, combined with examples for illustration from \cite{Labs1999}. To begin, Signature detection systems operate on an extremely basic principle: attacks that have been detected before should be recognizable after initially being discovered, assuming that whatever unique feature(s) that identify them are written down and matched against. Thus, a Signature-based IDS is one that maintains a database of attack signatures and matches against said database to flag unauthorized or potentially harmful activity on a system, determining if it is an attack at all (and which one it may be of thousands) by examining it side-by-side with each signature. 
	    	
	    	As an example, consider an exploit of Suidperl, a version of Perl that allows the execution of scripts that change user IDs and/or group IDs. Early versions of the Suidperl interpreter do not properly relinquish  root privileges when changing its effective user and group IDs. This allows the creation of a (two line!) script that simply presents the user with a root shell after execution. There are two main approaches to recognize this attack with a signature based IDS. The first is the more simple one, which is searching for strings that have no real use outside of such an attack, and thus can be used to uniquely identify a script that is intended to circumvent access control. The second is to analyze the system and confirm that a valid user-to-root transition has been made, as such sudden access control changes can be clearly identified in file system logs. It is worth noting at this juncture that though both of the above methods are valid to detect the example attack, and both are signature-based, deciding which approach to take is likely based on whether or not the IDS in use is a HIDS or a NIDS. The string-based identification method is better suited for a NIDS, as it can search network activity for strings such as "$>=0; $<=0;' or 'exec (æ/bin/sh');" that in all likelihood are an exploit attempt and not valid traffic. In contrast, a HIDS could check file systems logs and note that a root shell was spawned without any type of valid user to root transition, and notify authorities accordingly. 
	    	
	    	Naturally, no detection framework is perfect, and signature detection, by design, may contain critical flaws depending on how it is implemented. As one might expect, such flaws revolve around the fact that signatures are user-defined and maintained, and firm definitions of what uniquely identifies a signature and what does not is subjective to any given user. Therefore, it is easy to imagine the creation of a signature that defines and identifies a given attack with the utmost precision, but to a fault, such that the signature is so specific that it cannot identify even slight variations of the same attack. Similarly, though probably not as common to see as the previous flaw, signatures can be defined too nebulously. If a signature is not specific enough to a certain attack, and too broadly identifies common attributes between multiple attacks, it is just as problematic as a signature that cannot detect variations of the same attacks.
    	\subsubsection{Anomaly Detection}
    		Anomaly detecting systems work by constructing a system profile of "normal" behavior, and use that profile to then detect abnormal behavior. The idea is that attacks are a subset of abnormal behavior, which will allow these types of systems to detect them. Most of these systems use some complex statistical analysis to determine when activity differs from the system profile. The major draw to these types of systems is that, unlike signature detection methods, these systems can detect not only variations on known attacks, but completely novel attacks as well. The problem with this functionality is that it is predicated on having an effective system profile, which is by no means trivial to produce. They require extensive training sets to learn from, of which few exist. In practice, these types of systems produce large numbers of false positives that require manual inspection to effectively classify as an attack or not. For this reason, few existing systems use this type of detection. Instead IDSs using this type of detection mechanism are more an an open area of research than production level systems. 
    	\begin{figure}[h!]
			\centering
			\includegraphics[width=0.5\textwidth]{signatreVSanomaly.png}
			\caption{Summary of Event Analysis systems. Image taken from \cite{Alenezi2012}}
			\label{comparison}
	\end{figure}
\section{Related Work}
    % I think we want to model this section after [Bhuyan, Bhattacharyya, Kalitan]
    % Their paper is in the probes section of Mendeley,you should go check it out
    \subsection{Probes}
	 This section is will discuss various approaches to detecting Probe attacks. Probes have been classified as any passive information gathering intrusion. The most common form of probe attack, one which will be discussed at length, is the port scan. The motivation for detecting these types of scans is that any intelligent attacker wishing to launch a successful attack will gather background information about the victims system before launching his or her attack. Their primary means of gathering information is by first launching a port scan.
	 
	 There are 65,536 standardly defined ports on a given machine. These are broken down into three large categories: \emph{a.} Well-known ports(0-1,023), \emph{b.}Registered ports (1,024-49,151), \emph{c.} Dynamic and/or private ports (49,152-65,536) [Matiti, P Lecture notes from Surveying Port Scans Methodologies]. %TODO Cite this!
Essentially, a port scan consists of sending a message to each of these ports and analyzing the response message to gain information about what services the victim machine is running. For this reason, TCP ports are the most often scanned because TCP is a connection-oriented protocol, meaning that its response messages are more useful. Added to this, it is easy to block/detect UDP traffic at the firewall level \cite{Bhuyan2011}. In general, like most attacks, port scans can be broken down into to high level categories: single source, and distributed source. Within these categories, \cite{Staniford2002} further divides each of these categories into horizantal, vertical, stobe, and block scans based on the number of machines and ports scanned. A summary of these categories can be found in \ref{portScans}.
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.45\textwidth]{portScans.png}
		\caption{Summary of Port Scans. Image taken from \cite{Bhuyan2011}}
		\label{portScans}
	\end{figure}
	
	There is a great deal of research into detecting port scans. Several prominent authors' work will be discussed in the following sub section. They have been organized into signature-based, and anomaly-based detection scheme. \cite{Bhuyan2011} presents a much more rigorous taxonomy of detection methodologies that we leave up to all interested parties to explore. 
		\subsubsection{Signature-Based Detection}
		\begin{description}
			\item[] %Src 1
			\item[] %Src 2
		\end{description}
		\subsubsection{Anomaly-Based Detection}
		
    
    \subsection{Privilege Escalation} %Notes to be added at the end of this: shit is short because look at the discussion section, fucker.
    Privilege Escalation attacks are described in two general categories in this paper: Remote to User Attacks and User to Root Attacks. In the broadest sense, Remote to User Attacks are when an attacker seeks to gain local user access to a machine that they have network access to. A User to Root Attack, as one may infer from its name, is when an attacker who already possesses local user access seeks to escalate their privileges to those of a root user, IE gain root user access. In the following sections, both types of attacks are explained in detail.
    \subsubsection{Remote to User}
    A Remote to User attack is when an attacker who has network access to a system but does not have an account on that machine exploits a vulnerability on the system to gain unauthorized local access as a user of the target system. These types of attacks come in many forms, and can be as simple as getting valid user authentication information through guessing a user's password with a dictionary attack. However, just as common are attacks that exploit a vulnerability in a common and innocuous system service, such as FTP to gain local user access. These exploits can change system settings to allow an attacker remote access, but they can also trigger buffer overflows, which in many circumstances allow an attacker to execute arbitrary code on the remote host (which is often used to gain root access, as we will discuss later). 
    \subsubsection{User to Root}
     A User to Root attack is when an attacker who has no access or local user access to a system escalates their privileges to those of a root user. As with Remote to User attacks, User to Root attacks can come in a wide variety of formats. However, most of them tend to be some form of vulnerability exploit that either allows temporary root access (which is enough for any attacker to establish a backdoor for themselves for root access in the future), or triggers a buffer overflow, which can be used by a clever attacker to execute arbitrary code to gain root access. 
     \subsubsection{Detection}
     Currently, research on detection of Privilege Escalation attacks is fairly rudimentary. While a lot of research has been done examining  
    \subsection{Denial of Service}

\section{Methods}
    % This is where we should talk about why we broke attacks up the way that we 
    % did.

\section{Evaluation}
    % I am not so sure we even need this section, if we use it we could talk 
    % about the limitations of IDS's of something, the current state of affairs

\section{Discussion}
    % What would we say here?
    \subsection{Training Sets}
    \subsection{Effective Defense}
    \subsection{Open Problems}
    % J: Perhaps we could talk about need for attack categorization stuff here.

\section{Conclusions}
    % See outline for this bit

	% References-------------------------------
	%I produced all references, we invariably wont use all of them, but this makes it easier to cite things trhoughout the paper. At the end, we will re-Export the bibTex, to just be what we used by searching through this document for the work 'cite'
	
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{allSources}{}  % sigproc.bib is the name of the Bibliography in this case
\nocite{*}
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
\balancecolumns
\end{document}
